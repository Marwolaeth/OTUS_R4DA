---
title: "Линейная регрессия"
sutitle: "Теория и сравнение реализации"
author: "otus.ru"
format:
  html:
    theme:
      light: pulse
      dark: cyborg
  pdf:
    include-in-header:
      - file: ../tools/preamble.tex
execute:
  echo: true
  eval: true
  warning: false
---

## Линейная регрессия — классика машинного обучения

Линейная регрессия — это статистический метод, используемый для исследования отношений между зависимой переменной и одной или несколькими независимыми переменными. Он находит применение во многих областях, включая экономику, социологию, медицину и многие другие.

Модель простой линейной регрессии выглядит следующим образом:

$$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$

где $y_i$ — зависимая переменная, $x_i$ — независимая переменная, $\beta_0$ и $\beta_1$ — коэффициенты регрессии, а $\epsilon_i$ — случайная ошибка.

Модель множественной линейной регрессии можно записать в матричной форме:

$$y = X\beta + \epsilon$$

где $y$ — вектор зависимых переменных, $X$ — матрица независимых переменных, $\beta$ — вектор коэффициентов регрессии, и $\epsilon$ — вектор случайной ошибки.

Для оценки коэффициентов регрессии используется метод наименьших квадратов (OLS). Этот метод минимизирует сумму квадратов остатков, чтобы получить наилучшие оценки коэффициентов регрессии.

Для оценки коэффициентов регрессии также часто применяют QR-разложение матрицы $X$ или метод максимального правдоподобия.

Линейная регрессия может использоваться для прогнозирования значений зависимой переменной на основе известных значений независимых переменных, а также для изучения взаимосвязей между переменными.


